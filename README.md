# Twitter-vs-Bitcoin

По ссылке https://drive.google.com/drive/folders/12cFd9pmwBiQfuZQaX1NpfDBFoHQehqRq?usp=sharing:
1) Минутные данные по ценам и объемам торгов BTC/USD
2) ~1.5 млн. твитов
3) reddit/twitter with sentiment - основной массив данных + расчитанные сентименты
4) reddit/twitter with PCA - reddit/twitter with sentiment + PCA на feature extraction
5) reddit/twitter total X - reddit/twitter with PCA из которого мы взяли перекрестные произведения 2 переменных или квадрат одной
6) xgboost auto ml MAPE - MAPE для каждой отдельной переменной reddit/twitter total X 
7) instr - набор переменных, отобранный AUTO ML из пункта 5. Part 2.1
___________________________________________________________________________________________________________________________________________________________________________________
Part 1.
1) Парсинг твиттера и реддита
2) EDA по соотнисению численных переменных и сентиментов с доходностью и объемами торгов не даёт результатов.
3) |Корреляция|<0.1
___________________________________________________________________________________________________________________________________________________________________________________
Part 2.1.
Для каждого формата reddit (Daily, hourly, minutely):
1) Расчет сентиментов
2) Feature extraction - FeatureHasher/CountVectorizer/bigram_vectorizer
3) PCA для каждой переменной - 30 компонент
4) Сочетание переменных - перекрестные произведения 2 переменных или квадрат одной
5) AUTO ML - xgboost - для Daily формата на всей выборке, для остальных - на 30% наблюдений:
I) для каждой переменный расчитываем MAPE
II) сортируем массив переменных по возвостанию MAPE
III) увеличиваем набор переменных, поочередно включая новую, если её VIF<5

Для twitter :
1) Feature extraction - FeatureHasher/CountVectorizer/bigram_vectorizer
2) PCA для каждой переменной - 30 компонент
3) Сочетание переменных - перекрестные произведения 2 переменных или квадрат одной

Part 2.2.
1) Моделирование для reddit - xgboost - распределение predict повторяет распределения real. MAPE > 100%.
2) Моделирование для twitter - RNN - MAPE 98% - лучший результат. xgboost для Twitter показывает хорошие результаты на train, но на тесте то же, что и у reddit.
3) Дополнительно было выдвинуто предположение, что для экстримальных значений будет больше точность (за счет tolerance и меньшей доли шума), но результат для доходностей >95% и <5% не отличается.
___________________________________________________________________________________________________________________________________________________________________________________
Part 3.
1) BERT для задачи классификации (1,0) для положительных и отрицательных доходностей соответственно.

1.1) BERT с малым числом epoches и малым batch_size ~ 51%

1.2) BERT с большим числом epoches и большим batch_size ~ 51%

1.3) BERT с LogReg ~ 50.01%
